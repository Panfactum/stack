---
layout: '@/layouts/DocumentationLayout.astro'
title: 'Connect to Infrastructure'
---

import { Image } from 'astro:assets'
import MarkdownGuideNav from '@/components/markdown/MarkdownGuideNav'

import awsImg from './aws.jpg'
import dashboardImg from './dashboard.jpg'
import eksImg from './eks.jpg'
import k9sImg from './k9s.jpg'

# Connect to Infrastructure

## Objective

Retrieve credentials for connecting to the various components of your organization's infrastructure.

## User Provisioning

To access live infrastructure, you must first have an account in your organization's [identity provider (IdP)](https://en.wikipedia.org/wiki/Identity_provider). [^1]
This account with be used to sign in to all service providers.

[^1]: The IdP itself should have already been provisioned in the [bootstrapping guide.](/docs/edge/guides/bootstrapping/identity-provider)

If your organization's administrators have not already [provisioned your account](/docs/edge/guides/user-management/provisioning-new-user), ask them now. You
will need to follow [this guide](/docs/edge/guides/user-management/setting-up-new-user) to set up your user for the first time.

Once your user is provisioned, make sure you are able to access your organization's Authentik dashboard: [^2]

<Image src={dashboardImg} alt="Authentik dashboard" />

[^2]: If you are not sure the URL, ask an organization administrator or refer to your organization's internal documentation.

The applications you see will vary based on your organization's settings.

## Accessing AWS

If your organization granted you AWS access, you should see AWS in your Authentik dashboard. You can click on the app
to get brought to the access portal showing your individual account access:

<Image src={awsImg} alt="AWS access portal" />

Your visible accounts and roles will vary based on your organization's settings.

### AWS CLI Access

These accounts and roles are already available for use inside your local repository. They are configured under the `aws_dir` directory (defaults to `.aws`).

Access is made available via [AWS CLI/SDK profiles](https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-files.html). You
can view all your organization's profiles by running `aws configure list-profiles`.

Each profile is of the format `<account>-<role>`.

You may not have access to all of your organization's profiles. Check the access portal to see which accounts and roles
you can use.

You can set your active profile by setting the `AWS_PROFILE` environment variable (e.g., `export AWS_PROFILE=<your_profile>`)
or by passing the `--profile <your_profile>` flag to the `aws` CLI.

Let's confirm this works:

1. Set `AWS_PROFILE` to a profile you have access to.

2. Run `aws sso login` to complete the single sign-on verification.

3. Run `aws sts get-caller-identity`. This should successfully return a result that looks like this:

   ```shell-session
   891377197483    arn:aws:sts::891377197483:assumed-role/AWSReservedSSO_Superuser_ed8b0abf4bb50ae8/jack@panfactum.com     AROA47CRYUGV33VTVQCPO:jack@panfactum.com
   ```

## Accessing Kubernetes

For each AWS account that you have access to, you can view the information about their deployed Kubernetes clusters via
the Web UI: [^3]

1. Log into an account

2. Navigate to the appropriate AWS region (top right dropdown)

3. Navigate to the Elastic Kubernetes Service (EKS) page (via the search box)

4. Select a cluster

5. You should see a dashboard that looks like this:

   <Image src={eksImg} alt="EKS dashboard" />

[^3]:
    You can see what accounts and regions your clusters are deployed to by examining the `environments_dir` folder in your
    repository (defaults to `environments`). SearchButton for `aws_eks` module folders. Ask an organization administrator if your need further guidance.

### Kubernetes CLI Access

The above dashboard is read-only. If you want to make changes to your cluster, you will need to access your clusters from the CLI.
This will require setting up your [kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/) file.

We provide an easy way to do this by performing the following actions within your organization's repository:

1. Copy the `config.user.example.yaml` file in your `kube_dir` folder (defaults to `.kube`) to `config.user.yaml`.

2. Update the `config.user.yaml` to include the clusters you want to access and what AWS profile you want to use for that access. See
   the [reference docs](/docs/edge/reference/configuration/kubernetes#config.user.yaml) for the specific syntax.

3. Run `pf-update-kube` to create your kubeconfig file.

4. Select a cluster context by running `kubectx`.

5. Run `kubectl cluster-info` and you should see a successful result like the following:

   ```shell-session
   Kubernetes control plane is running at https://83063DDB274B2A04B6A7DC29DCB1740E.gr7.us-east-2.eks.amazonaws.com
   CoreDNS is running at https://83063DDB274B2A04B6A7DC29DCB1740E.gr7.us-east-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

   To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
   ```

In the Panfactum stack, we highly recommend [k9s](https://k9scli.io/) as the tool for interactively interfacing with your Kubernetes clusters. We
will reference it often in our documentation, so you should gain familiarity.

Launch it now via `k9s`:

<Image src={k9sImg} alt="EKS dashboard" />

## Next Steps

ðŸŽ‰ You are now all set up to begin working with live infrastructure in the Panfactum stack. ðŸŽ‰

Here are some ideas for next steps:

- [Learn how to deploy infrastructure using infrastructure-as-code](/docs/edge/guides/iac/deploying-modules)

- [Customize your organization's devShell](/docs/edge/guides/development-shell/customizing)

- [Connect to databases](/docs/edge/guides/networking/database-connections)

<MarkdownGuideNav
  backHref={'/docs/edge/guides/getting-started/boot-developer-environment'}
  stepNumber={4}
  totalSteps={4}
  progressLabel={'Getting Started Guide:'}
/>
