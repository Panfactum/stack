import ModuleHeader from "../../../ModuleHeader";

{/* lint disable no-duplicate-headings */}

{/* eslint-disable import/order */}

<ModuleHeader name="kube_karpenter_node_pools" sourceHref="https://github.com/Panfactum/stack/tree/__PANFACTUM_VERSION_EDGE__/packages/infrastructure/kube_karpenter_node_pools" status="stable" type="direct" />

# Karpenter NodePools

This module provisions Karpenter [NodePools](https://karpenter.sh/docs/concepts/nodepools/) and [NodeClasses](https://karpenter.sh/docs/concepts/nodeclasses/)
that allow Karpenter to manage EC2 instances.

## Usage

### Limiting Maximum Node Size

Due to [this issue](https://github.com/aws/karpenter-provider-aws/issues/7254), we have observed that Karpenter
will occasionally provision extremely large nodes for no apparent reason. As a mitigation, we have
two variables, `max_node_memory_mb` and `max_node_cpu`, that limit the maximum size of nodes that can be provisioned.

If you need larger nodes than the default set by this module, you will need to adjust those limits.

## Providers

The following providers are needed by this module:

* [aws](https://registry.terraform.io/providers/hashicorp/aws/5.80.0/docs) (5.80.0)

* [kubectl](https://registry.terraform.io/providers/alekc/kubectl/2.1.3/docs) (2.1.3)

* [kubernetes](https://registry.terraform.io/providers/hashicorp/kubernetes/2.34.0/docs) (2.34.0)

* [pf](https://registry.terraform.io/providers/panfactum/pf/0.0.4/docs) (0.0.4)

* [random](https://registry.terraform.io/providers/hashicorp/random/3.6.3/docs) (3.6.3)

## Required Inputs

The following input variables are required:

### cluster\_ca\_data

Description: The B64 encoded CA data of the API server of the eks cluster

Type: `string`

### cluster\_dns\_service\_ip

Description: The IP address of the cluster's DNS service.

Type: `string`

### cluster\_endpoint

Description: The URL of the API server of the eks cluster

Type: `string`

### cluster\_name

Description: The name of the eks cluster

Type: `string`

### node\_instance\_profile

Description: The instance profile to use for launched nodes

Type: `string`

### node\_security\_group\_id

Description: The id of the security group for nodes running in the EKS cluster

Type: `string`

### node\_subnets

Description: List of subnet names to deploy Karpenter nodes into.

Type: `set(string)`

### node\_vpc\_id

Description: The ID of the VPC to deploy Karpenter nodes into.

Type: `string`

## Optional Inputs

The following input variables are optional (have default values):

### max\_node\_cpu

Description: The maximum number of CPUs for any single provisioned node (in MB)

Type: `number`

Default: `32`

### max\_node\_memory\_mb

Description: The maximum memory for any single provisioned node (in MB)

Type: `number`

Default: `65536`

### monitoring\_enabled

Description: Whether to active monitoring has been added to the cluster

Type: `bool`

Default: `false`

### node\_ebs\_volume\_size\_gb

Description: The size of the EBS volume in GiB to use for each node.

Type: `number`

Default: `40`

### node\_labels

Description: Labels to apply to nodes generated by Karpenter

Type: `map(string)`

Default: `{}`

## Outputs

The following outputs are exported:

### user\_data

Description: n/a

## Maintainer Notes

We make heavy use of `random_id` and `create_before_destroy` because Karpenter often updates its CRD spec,
and changes to this spec requires destroying old CRs. However, we cannot just naively destroy these CRs as (a) destroying
a CR de-provisions all nodes created by it and (b) destroying all CRs at once would leave Karpenter unable
to create new nodes for the disrupted pods. Obviously this is not desirable in a live cluster.

As a result, we
create new CRs **before** destroying the old ones so that when we destroy the old ones, Karpenter can
create new nodes for the disrupted pods.

{/* eslint-enable import/order */}

{/* lint enable no-duplicate-headings */}
