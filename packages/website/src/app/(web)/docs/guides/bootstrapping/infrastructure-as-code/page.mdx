import s3BucketInitImg from './s3-bucket-init.jpg'
import firstTfStateImg from './first-tf-state.jpg'
import MarkdownImage from "@/components/markdown/MarkdownImage";
import MarkdownAlert from "@/components/markdown/MarkdownAlert";

# Bootstrapping Infrastructure-as-Code

## Objective

Complete the necessary setup to begin utilizing terraform and terragrunt.

## Background

If you're new to using infrastructure-as-code tooling professionally, you should review the
concepts documentation before continuing (TODO).

Because both terraform and terragrunt are **unopinionated tools**,
every organization tends to implement infrastructure-as-code differently. There is no
right or wrong approach, but it is tedious and error-prone to invent one from scratch.

As a result, the Panfactum stack provides
standardization with a **highly opinionated set of practices** for deploying infrastructure-as-code
that incorporates dozens of lessons learned over the past decade. It aligns with the recommendations
provided by both Hashicorp (terraform) and Gruntworks (terragrunt).

We assume that you will build upon the framework we provide
as you begin to deploy infrastructure. We provide CLI tooling that enables you to quickly scaffold out
your project to align with our guides. As you become comfortable working in the stack,
you may customize any part of our starting setup to fit your organization's evolving needs.

**Regardless of whether you have used terraform and/or terragrunt before, you should
review the [Panfactum terraforming guides](../terraforming/overview).**

## Set Up Environments Directory

Please ensure you have completed the following sections of the [Deploying Modules guide](../terraforming/deploying-modules):
    - _Setting up Your Repo_
    - _Terragrunt Setup_

After completing those sections, you should have a fully scaffolded environments
directory. Please validate the following statements about this directory:

- It contains a `panfactum.hcl`.
- It contains a `global.yaml`.
- It contains a `providers` directory with several providers such as `aws.tf`.
- You have a top-level directory for **every** environment we created in the previous _Preparing AWS_ guide.
- Each environment directory contains an `environment.yaml` file.
- Each environment directory contains a region directory for **every** AWS region you want to deploy infrastructure
into. Additionally, you have a region directory called `global` inside of every environment directory.
- Each region directory contains a `region.yaml` file.

Finally, ensure that you do **not** receive any warnings about needing to run `pf-terragrunt-update` when opening
the repository in your terminal.

Ultimately, your environments folder should closely resemble that of
[our reference architecture](https://github.com/Panfactum/stack/tree/main/packages/reference/environments).

## Configure Terragrunt Variables

In order to begin deploying terraform modules, we must first configure terragrunt via our terragrunt variables
which will be set in the `global.yaml`, `environemnt.yaml`, and `region.yaml` files
(see [reference docs](http://localhost:3000/docs/reference/terragrunt-variables)).

### Metadata

The following metadata fields are used for tagging and labeling deployed infrastructure:

- In **every** `environment.yaml` file, set the `environment` key to the name of the environment
(typically the same as the directory name)
- In **every** `region.yaml` file, set the `region` key to the name of the region (typically the same as the directory name)

### State Backend

Each environment will have its own, **independent** [terraform backend](https://developer.hashicorp.com/terraform/language/settings/backends/configuration)
for storing information about the tracked terraform resources. We utilize the [S3 backend](https://developer.hashicorp.com/terraform/language/settings/backends/s3)
and store the state for each environment inside of that environment's AWS account.

In **every** environment.yaml, set the following keys:

- `tf_state_account_id`: Set this to the account id for the environment's AWS account
- `tf_state_profile`: Set this to the AWS profile name you created for accessing this account in the _Preparing AWS_ guide
- `tf_state_region`: Set this your primary AWS region (buckets have to have an assigned region even though we use it for deploying resources to _all_ regions in the environment)
- `tf_state_bucket`: Set the name of the S3 bucket you want to use. Should not exist yet and must be globally unique. Example: `my-company-terraform-state-development`.
- `tf_state_lock_table`: Set the name of the DynamoDB table you want to use. Should not exist yet and must be globally unique. Example: `my-company-terraform-state-development`.

### AWS Provider

These variables will configure how the terraform AWS provider deploys resources into AWS and will vary its behavior
based on the folder the terraform module is deployed from.

In **every** `environment.yaml` file, set the following keys:

- `aws_account_id`: Set this to the account id for the environment's AWS account.
- `aws_profile`: Set this to the AWS profile name you created for accessing this account in the _Preparing AWS_ guide.
- `aws_secondary_account_id`: Set this to the `aws_account_id` from above.
- `aws_secondary_profile`: Set this to the `aws_profile` from above.

In **every** `region.yaml` file, set the following keys:

- `aws_region`: Set this to the AWS region code for the directory (e.g., `us-west-2`). For the `global` region,
set the region to your primary AWS region which would normally be what you used for `tf_state_region` above.
- `aws_secondary_region`: Set this to the `aws_region` from above.

_The secondary values are used by some modules that configure resources in multiple AWS accounts or regions. What we
have just done is default them to primary values, and we will override them on a per-module basis as needed._

## Bootstrap State Backends

To begin deploying infrastructure, you will first need a terraform state backend... which is itself infrastructure.
In fact, we provide a terraform module for setting up the backend: [terraform_bootstrap_resources](../../reference/terraform-modules/terraform_bootstrap_resources).

This creates a circular dependency that we will resolve as follows:

1. Use terragrunt's built-in S3 backend generation to build the state backend.
2. Import those autogenerated resources into a deployment of `terraform_bootstrap_resources`.
3. Apply the `terraform_bootstrap_resources` module to deploy the Panfactum-provided enhancements.

### Create the State Backend for Management Environment

Terragrunt will [automatically generate the resources](https://terragrunt.gruntwork.io/docs/features/keep-your-remote-state-configuration-dry/#create-remote-state-and-locking-resources-automatically)
required to bootstrap an S3 terraform backend if they do not already exist. This greatly simplifies the bootstrapping process.

To take advantage of this, we will create our first terragrunt deployment:

1. Generate a deployment directory for [terraform_bootstrap_resources](../../reference/terraform-modules/terraform_bootstrap_resources):
`environments/management/global/terraform_bootstrap_resources`
2. Add a `terragrunt.hcl` to that directory:

    ```hcl
    include "panfactum" {
        path = find_in_parent_folders("panfactum.hcl")
        expose = true
    }

    terraform {
      source = "github.com/Panfactum/stack.git?ref=__currentPanfactumVersion__/packages/terraform//terraform_bootstrap_resources"
    }

    inputs = {
        state_bucket = include.panfactum.locals.vars.tf_state_bucket
        lock_table   = include.panfactum.locals.vars.tf_state_lock_table
    }
    ```
3. Add a `module.yaml` to that directory that enables the `aws` terraform provider:

    ```yaml
    providers:
      - aws
    ```

4. Open your terminal to that directory and run `terragrunt init`. If your system is setup correctly, you should
see a prompt like the following:

    ```shell-session
    Remote state S3 bucket panfactum-tf-state-management does not exist or you don't have permissions to access it. Would you like Terragrunt to create it? (y/n)
    ```

5. Type `y` and press enter. If everything completes successfully you should see a message such as

    ```shell-session
    Initializing the backend...

    Successfully configured the backend "s3"! Terraform will automatically
    use this backend unless the backend configuration changes.

    Initializing provider plugins...
    - Finding hashicorp/aws versions matching "~> 4.13"...
    - Installing hashicorp/aws v4.67.0...
    - Installed hashicorp/aws v4.67.0 (signed by HashiCorp)

    Terraform has created a lock file .terraform.lock.hcl to record the provider
    selections it made above. Include this file in your version control repository
    so that Terraform can guarantee to make the same selections by default when
    you run "terraform init" in the future.

    Terraform has been successfully initialized!

    You may now begin working with Terraform. Try running "terraform plan" to see
    any changes that are required for your infrastructure. All Terraform commands
    should now work.

    If you ever set or change modules or backend configuration for Terraform,
    rerun this command to reinitialize your working directory. If you forget, other
    commands will detect it and remind you to do so if necessary.
    ```

6. Navigate to _S3_ in the AWS console. You should see an **empty** S3 bucket that terragrunt just instantiated.

    <MarkdownImage src={s3BucketInitImg} alt={"Initialized S3 bucket"} />

### Import the Autogenerated Resources

While terragrunt autogenerated the minimum necessary resources, they are **not** yet being managed by your
`terraform_bootstrap_resources` module.[^1] We will need to [import them into terraform](https://developer.hashicorp.com/terraform/cli/import).

[^1]: Technically, the module hasn't even been deployed yet. It has only been initialized locally on your machine.

1. Run the following series of commands:

    ```shell-session
    terragrunt import aws_s3_bucket.state <tf_state_bucket>
    terragrunt import aws_dynamodb_table.lock <tf_state_lock_table>
    ```

    Replace `<tf_state_bucket>` and `<tf_state_lock_table>` with your state bucket name and lock table name respectively.

2. If your import is successful, you should have your first state file.

    <MarkdownImage src={firstTfStateImg} alt={"First terraform state file"} />

3. Run `terragrunt apply` to synchronize the resources with the `terraform_bootstrap_resources` module. This module
adds several enhancements above and beyond the basic autogenerated resources created by terragrunt.

    This _may_ result in an error `Error: Error releasing the state lock`. This is because we update the DynamoDB lock
    table to enabled multi-region replication. This is a benign error, and no action is needed.

4. Run `terragrunt plan`. You should see the following message: `No changes. Your infrastructure matches the configuration.`.
Congratulations! You have successfully deployed your first terraform module in the Panfactum stack. ðŸŽ‰ ðŸ¥³ ðŸŽ‰

### Bootstrap other Environments

Now you will boostrap the state backends for your other environments by repeating the process above
for **every** environment. You can simply copy the `terraform_boostrap_resources` directory into the
equivalent location in every other environment to get started.

## Setup sops

Terragrunt uses [sops](https://github.com/getsops/sops) to store secret configuration values. This allows you to commit
secrets _in encrypted form_ directly to version control which comes with a host of benefits:

- All of your settings for all infrastructure can now be found in a _single_ location.
- You do not need a separate change management or CI/CD process for secrets and non-secret values.
- You will implicitly have an audit log of all changes.
- You can utilize sops for other git ops activities in addition to deploying terraform (e.g., performing automatic
rotations).

We will configure sops to use _AWS KMS_ for the encryption keys. This provides several benefits:

- sops uses _transit encryption_. As a result, the encryption keys never leave the key store. By using KMS, _noone_
in your organization will ever have access to the encryption keys which means you do not need to rotate
these keys (and thus all secrets encrypted with them) every time you offboard a member of your organization.
- KMS allows you to replicate the encryption keys across multiple regions, ensuring you will never lose access.
- KMS will provide an audit log for every time a secret value is _accessed_ which will augment the `git` commit history that
records every time a secret is changed.
- Access to each KMS key will inherit our AWS role-based access control paradigm. As keys are scoped to each environment,
access to secrets will automatically align with environment permissions. In other words, users with access
to development will have access to development secrets but not necessary secrets in other environments.

Let's set this up.

1. In **every environment**, create a deployment of the [aws_kms_encrypt_key](../../reference/terraform-modules/aws_kms_encrypt_key) module.

    1. Add a new directory called `sops` to the `global` region.

    2. Add a `terragrunt.hcl`:

        ```hcl

        include "panfactum" {
            path = find_in_parent_folders("panfactum.hcl")
            expose = true
        }

        terraform {
            source = "github.com/Panfactum/stack.git?ref=__currentPanfactumVersion__/packages/terraform//aws_kms_encrypt_key"
        }

        inputs = {
            name = "sops-${include.panfactum.locals.vars.environment}"
            description   = "Encryption key for sops"
        }
       ```

    3. Enable the `aws` provider in a `module.yaml`:

        ```yaml
        providers:
          - aws
        ```

    4. Run `terragrunt apply`. Take note of **both** the `arn` and `arn2` outputs as we will need in a following step.

2. In the **root of your repo**, we will create a `.sops.yaml` configuration file. This will enable you to easily assign
KMS keys to the secrets you create based on the secret's file name.

    Under the `creation_rules` key, you will add an array element for **every** environment that is an object that has the form:

    ```yaml
    path_regex: .*/<environment>/.*
    aws_profile: <environment>-superuser
    kms: '<arn>,<arn2>'
    ```

    Replace `<environment>` with the name of the environment. Replace `<arn>` and `<arn2>` with the ARN outputs from the deployment
    step.

    Ultimately, you should construct a file that looks like [this](https://github.com/Panfactum/stack/blob/__currentPanfactumVersion__/packages/reference/.sops.yaml).

3. Let's perform a quick test to ensure sops is working properly.

    1. Create a new file at `environments/management/test.yaml`:

        ```yaml
        foo: bar
        ```

    2. Run `sops -e -i test.yaml` ((e)ncrypt (i)n-place). The file contents should be transformed into something like the following:

        ```yaml
        foo: ENC[AES256_GCM,data:JJWK,iv:iF2zywZM3DWObiJCPsaPzETwnlQ1q2lh+zgHfCmk/PM=,tag:m2Ii1IlH05fT/TE4SStWIA==,type:str]
        sops:
            kms:
              - arn: arn:aws:kms:us-east-2:143003111016:key/mrk-955687aaf5124a07837ae4e2a442f8ec
                created_at: "2024-03-08T17:27:00Z"
                enc: AQICAHgMz35tnCYOcZgsSkZfKep5SPbKOCK5kzijAQLnZXO3TAHQ6ctemzPMzRenMG2LWQjAAAAAfjB8BgkqhkiG9w0BBwagbzBtAgEAMGgGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM4JXy9Gd99htGiu7aAgEQgDuxh107pk18bFU5Q8vzeu1rI+u6+/7s7Xao5DUSE/86Uyvo7USMny58KqJnqUdIvGmj3xYqV5dVMGJxAQ==
                aws_profile: management-superuser
              - arn: arn:aws:kms:us-west-2:143003111016:key/mrk-955687aaf5124a07837ae4e2a442f8ec
                created_at: "2024-03-08T17:27:00Z"
                enc: AQICAHgMz35tnCYOcZgsSkZfKep5SPbKOCK5kzijAQLnZXO3TAFwqRvjtwaFuBNp9ppYc58OAAAAfjB8BgkqhkiG9w0BBwagbzBtAgEAMGgGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMagf0c2ADsKLKXBFQAgEQgDsP5rqepGI3MvwhtRVxmS6/hyWWDyqEbOIxYS1WybNinBggkfKNRTw0Z8vob2tuSg5ZUeRpABry/C84PA==
                aws_profile: management-superuser
            gcp_kms: []
            azure_kv: []
            hc_vault: []
            age: []
            lastmodified: "2024-03-08T17:27:01Z"
            mac: ENC[AES256_GCM,data:JwzOMNKLn5ETSQY6QiGmxkxLqzX6buvs5OccPZ/BVOdfvgUW8vsgv34l6UiOidHq71GeGo5G9sPHeNiFGWPgqBMNU/qUugt9qldHs5k/oo6e4wFIzOxkIT2NZ1CmLw/9vxw8ZWskWX43XPC8tQlu9NmxE65G7NSDTaHBIFVVG44=,iv:L1pBiv+2y066RNr9qppBjuCjgLkaui6yOGJ6iPSCg8w=,tag:kmN5KBJ7gkhvcnkV67/xjw==,type:str]
            pgp: []
            unencrypted_suffix: _unencrypted
            version: 3.8.1
        ```

        This file is now **safe** to commit to version control.

    3. Run `sops -d test.yaml` ((d)ecrypt). Notice the original file contents should have been output to your terminal.

    4. Delete the file.


## Deploy the AWS Account Module

Now that you have both the state backends and encryption keys established, we will put them both to use in deploying
the [aws_account](../../referenace/terraform-modules/aws_account) module. This module adds some critical metadata
to your account including setting up its alias and contact information.

Let's set it up.

1. In **every** environment's `global` region, create an `aws_account` directory.

2. Add a `terragrunt.hcl` to the directory:

    ```hcl
    include "panfactum" {
        path = find_in_parent_folders("panfactum.hcl")
        expose = true
    }

    terraform {
        source = "github.com/Panfactum/stack.git?ref=__currentPanfactumVersion__/packages/terraform//aws_kms_encrypt_key"
    }

    locals {
        secrets = yamldecode(sops_decrypt_file("${get_terragrunt_dir()}/secrets.yaml"))
    }

    inputs = {
        alias = "panfactum-${include.panfactum.locals.vars.environment}"

        contact_company_name = "Panfactum, LLC"
        contact_website = "https://panfactum.com"
        contact_full_name = "Jack Langston"
        contact_address_line_1 = local.secrets.address_line_1
        contact_city = local.secrets.city
        contact_district_or_county = local.secrets.district_or_county
        contact_state_or_region = local.secrets.state_or_region
        contact_postal_code = local.secrets.postal_code
        contact_country_code = "US"
        contact_phone_number = local.secrets.phone_number

        security_full_name = "Jack Langston"
        security_title     = "Captain"
        security_phone_number = local.secrets.phone_number
        security_email_address = local.secrets.email_address

        billing_full_name = "Jack Langston"
        billing_title     = "Captain"
        billing_phone_number = local.secrets.phone_number
        billing_email_address = local.secrets.email_address

        operations_full_name = "Jack Langston"
        operations_title     = "Captain"
        operations_phone_number = local.secrets.phone_number
        operations_email_address = local.secrets.email_address
    }
    ```

    Note the addition of this line `secrets = yamldecode(sops_decrypt_file("secrets.yaml"))` which demonstrates how
    terragrunt and sops integrate with one another.

    Replace the values as needed for your organization. Feel free to also change what values are secret or not.

3. Add a `module.yaml` with the `aws` provider enabled.

4. Add a `secrets.yaml` to the directory:

    ```yaml
    address_line_1: 1234 Platform Engineering Way
    city: Developer Junction
    district_or_county: Marion
    state_or_region: CA
    postal_code: "12345"
    phone_number: "+15555555555"
    email_address: spam@panfactum.com
    ```

    Adjust the values as necessary.

5. Run `sops -d -i secrets.yaml` to encrypt the file.

6. Run `terragrunt apply`.

<MarkdownAlert severity="warning">
    Because the KMS key ARNs are embedded in every encrypted sops file, you **cannot** simply copy and paste the secrets files
    across environments as they will still be bound to the original environment. If you need to copy secrets to another
    environment, first decrypt the file (`sops -d`), then copy it to the proper directory, then encrypt it (`sops -e -i`).
</MarkdownAlert>

## Next Steps

Now that you are set up to deploy infrastructure-as-code, we are ready to [setup DNS](./dns).




