import MarkdownImage from "@/components/markdown/MarkdownImage.astro";

import ciliumLaunchImg from './cilium-launch.jpg'
import corednsImg from './coredns.jpg'
import nodesReadyImg from './nodes-ready.jpg'
import BootstrappingGuideNav from "../BootstrappingGuideNav";

# Internal Cluster Networking

<p class="subtitle">Install the basic Kubernetes cluster networking primitives via the [kube\_core\_dns](/main/reference/infrastructure-modules/direct/kubernetes/kube_core_dns)
and [kube\_cilium](/main/reference/infrastructure-modules/direct/kubernetes/kube_cilium) modules.</p>

## Background

In the Panfactum framework, we use [CoreDNS](https://coredns.io/) to handle
cluster DNS resolution and [Cilium](https://docs.cilium.io) to handle all the L3/L4 networking in our Kubernetes cluster.

In this guide, we won't go into detail about the underlying design decisions and network concepts, so
we recommend reviewing the [concept documentation](/main/concepts/networking/cluster-networking) for more
information.

## Deploy Cilium

Cilium provides workloads in your clusters with network interfaces that allow them to connect with each other and the wider
internet. Without this controller, your pods would not be able to communicate. We provide a module
for deploying Cilium: [kube\_cilium](/main/reference/infrastructure-modules/direct/kubernetes/kube_cilium).

Let's deploy it now.

### Deploy the Cilium Module

1. Create a new directory adjacent to your `aws_eks` module called `kube_cilium`.

2. Add a `terragrunt.hcl` to that directory that looks like this:

   ::: code-group labels=\[kube\_cilium/terragrunt.hcl]

   ```hcl collapse={1-14} "REPLACE_ME"
   include "panfactum" {
      path   = find_in_parent_folders("panfactum.hcl")
      expose = true
   }

   terraform {
      source = include.panfactum.locals.pf_stack_source
   }

   dependency "cluster" {
      config_path  = "../aws_eks"
      skip_outputs = true
   }

   inputs = {}
   ```

   :::

3. Run `pf-tf-init` to enable the required providers.

4. Run `terragrunt apply`.

5. If the deployment succeeds, you should see the various cilium pods running:

   <MarkdownImage src={ciliumLaunchImg} alt="Cilium launched successfully" />

   Additionally, all the nodes should now be in the `Ready` state:

   <MarkdownImage src={nodesReadyImg} alt="Nodes are ready" />

## Deploy CoreDNS

Kubernetes provides human-readable DNS names for pods and services running inside the cluster (e.g., `my-service.namespace.svc.cluster.local`);
however, it does not come with its own DNS servers. The standard way to provide this functionality is via CoreDNS.
We provide a module to deploy CoreDNS called [kube\_core\_dns](/main/reference/infrastructure-modules/direct/kubernetes/kube_core_dns).

Let's deploy it now.

### Deploy the CoreDNS Module

1. Create a new directory adjacent to your `aws_eks` module called `kube_core_dns`.

2. Add a `terragrunt.hcl` to that directory that looks like this:

   ::: code-group labels=\[kube\_core\_dns/terragrunt.hcl]

   ```hcl collapse={1-9} "REPLACE_ME"
   include "panfactum" {
      path   = find_in_parent_folders("panfactum.hcl")
      expose = true
   }

   terraform {
      source = include.panfactum.locals.pf_stack_source
   }

   dependency "cluster" {
      config_path  = "../aws_eks"
   }


   inputs = {
      service_ip = dependency.cluster.outputs.dns_service_ip
   }
   ```

   :::

3. Run `pf-tf-init` to enable the required providers.

4. Run `terragrunt apply`.

5. If the deployment succeeds, you should see a `core-dns` deployment with either 1/2 or 2/2 pods running:

   <MarkdownImage src={corednsImg} alt="CoreDNS launched successfully" />

   If you see only 1/2 pods running, that is because we force the CoreDNS pods to run on nodes with different instance types
   for high-availability. However, the cluster won't be able to dynamically provision the new instance types until
   you complete the [autoscaling section](/main/guides/bootstrapping/autoscaling) of the bootstrapping guide.
   Once you complete that guide section, you will see that both CoreDNS pods have launched successfully. This should
   not have any impact in the interim.

### Next Steps

Now that basic networking is working, we will configure a policy engine for the cluster.

<BootstrappingGuideNav backHref={"/docs/main/guides/bootstrapping/kubernetes-cluster"} forwardHref={"/docs/main/guides/bootstrapping/policy-controller"} stepNumber={9} />
